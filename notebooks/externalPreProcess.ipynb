{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following code is for external data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 22:26:46 WARN Utils: Your hostname, DESKTOP-3NQ3PQI resolves to a loopback address: 127.0.1.1; using 172.31.183.205 instead (on interface eth0)\n",
      "22/09/22 22:26:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 22:26:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/09/22 22:26:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/09/22 22:26:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2 Preprocessing\")\n",
    "    .config(\"spark.driver.memory\", '4g')\n",
    "    .config(\"spark.executor.memory\", '8g')\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Postcode to ABS Postal Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postcode_to_str(col):\n",
    "    return col.astype(str).str.zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "postal_areas_gdf = gpd.read_file('../data/raw/postcodes/abs_postal_areas.zip')\n",
    "consumer_details_df = pd.read_parquet('../data/curated/cleaned_consumers.parquet')\n",
    "postcode_df = pd.read_csv('../data/raw/postcodes/postcodes.csv').drop_duplicates('postcode')\n",
    "\n",
    "consumer_details_df['postcode'] = postcode_to_str(consumer_details_df['postcode'])\n",
    "postcode_df['postcode'] = postcode_to_str(postcode_df['postcode'])\n",
    "\n",
    "# Convert postcode dataframe to geodataframe\n",
    "postcode_gdf = gpd.GeoDataFrame(\n",
    "    postcode_df, geometry=gpd.points_from_xy(postcode_df['long'], postcode_df['lat'])\n",
    ")\n",
    "postcode_gdf.crs = postal_areas_gdf.crs\n",
    "\n",
    "# Get list of postcodes not listed as abs postal areas and filter geodataframe to just these postcodes\n",
    "unmapped = consumer_details_df[~consumer_details_df['postcode'].astype(str).str.zfill(4).isin(postal_areas_gdf['POA_CODE21'])]['postcode'].unique()\n",
    "postcodes_gdf = postcode_gdf[postcode_gdf['postcode'].isin(unmapped)]\n",
    "\n",
    "# Spatially join unmapped postcodes and abs postal areas\n",
    "postcode_poa_gdf = postcodes_gdf.sjoin(postal_areas_gdf, how = 'inner')\n",
    "\n",
    "# Remove and rename columns \n",
    "postcode_poa_df = postcode_poa_gdf[['postcode', 'POA_CODE21']]\n",
    "postcode_poa_df = postcode_poa_df.rename(columns = {'POA_CODE21' : 'poa'})\n",
    "\n",
    "# Combine abs mapped postcodes with unmapped postcodes\n",
    "postcode_poa_df = pd.concat([postcode_poa_df, postal_areas_gdf[['POA_CODE21', 'POA_CODE21']].set_axis(['postcode', 'poa'], axis = 1)], ignore_index = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../data/curated/census/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "postcode_poa_df.to_parquet(output_dir + 'postcode_poa.parquet', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but 2 postcodes could be mapped to abs postal areas. Niether of these could be found in the Australia post website. https://postcodes-australia.com/postcodes/6958 says 6958 is a Western Australian postcode reserved for non standard use<br><br>\n",
    "This results in the removal of 317 consumers from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_consumers = consumer_details_df[~consumer_details_df['postcode'].astype(str).str.zfill(4).isin(postcode_poa_df['postcode'])]\n",
    "len(removed_consumers), removed_consumers['postcode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age/Gender Weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "transaction_sdf = spark.read.parquet(\n",
    "    '../data/tables/transactions_20210228_20210827_snapshot/'\n",
    ").union(\n",
    "    spark.read.parquet(\n",
    "        '../data/tables/transactions_20210828_20220227_snapshot/'\n",
    "    )\n",
    ").union(\n",
    "    spark.read.parquet(\n",
    "        '../data/tables/transactions_20220228_20220828_snapshot/'\n",
    "    )\n",
    ")\n",
    "\n",
    "id_df = pd.read_parquet(\n",
    "    '../data/tables/consumer_user_details.parquet'\n",
    ")\n",
    "\n",
    "consumer_df = pd.read_parquet(\n",
    "    '../data/curated/cleaned_consumers.parquet'\n",
    ")\n",
    "\n",
    "age_df = pd.read_parquet(\n",
    "    '../data/curated/census/age_data.parquet'\n",
    ")\n",
    "\n",
    "postcode_poa_df = pd.read_parquet(\n",
    "    '../data/curated/census/postcode_poa.parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate population by age intervals (18-24, 25-34, 35-44, 45-54, 55-64, 65+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for start_yr, end_yr in zip([18,25,35,45,55], [25,35,45,55,65]):\n",
    "    for g in ['m', 'f']:\n",
    "        col = f'age_{start_yr}_{end_yr - 1}_{g}'\n",
    "        cols.append(col)\n",
    "        age_df[col] = age_df.filter(regex = '|'.join([f'(age_yr_{x}_{g})'for x in range(start_yr,end_yr)])).astype(int).sum(axis = 1)\n",
    "\n",
    "for g in ['m', 'f']:\n",
    "    col = f'age_65+_{g}'\n",
    "    cols.append(col)\n",
    "    age_df[col] = age_df.filter(regex = '|'.join([f'(age_yr_{x}_{x+4}_{g})'for x in range(65,100, 5)] + ['age_yr_100_yr_over_[mf]'])).astype(int).sum(axis = 1)\n",
    "\n",
    "\n",
    "age_df = age_df[['poa'] + cols].melt(id_vars = 'poa')\n",
    "age_df['gender'] = age_df['variable'].apply(lambda x : 'Male' if x[-1] == 'm' else 'Female')\n",
    "age_df['variable'] = age_df['variable'].apply(lambda x : x[:-2])\n",
    "age_df = pd.pivot_table(age_df, values = 'value', index =['poa', 'gender'], columns='variable')\n",
    "\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "aus_age_m = age_df.loc[idx[:, 'Male'], :].sum()\n",
    "aus_age_f = age_df.loc[idx[:, 'Female'], :].sum()\n",
    "\n",
    "aus_prob_m = aus_age_m.sum()/(aus_age_m.sum() + aus_age_f.sum())\n",
    "\n",
    "aus_age_m *= 1/aus_age_m.sum()\n",
    "aus_age_f *= 1/aus_age_f.sum()\n",
    "\n",
    "\n",
    "age_df = age_df.apply(lambda x : x/x.sum(), axis = 1)\n",
    "age_df = age_df.fillna(age_df.mean())\n",
    "age_df = age_df.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ABS postal area (poa) to each consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_df = pd.merge(consumer_df, postcode_poa_df, how = 'inner', on = 'postcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe grouped by merchant and postal area (poa) with propn of customers for each corresponding postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                  (0 + 8) / 8][Stage 8:>                  (0 + 0) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 22:28:05 WARN TaskSetManager: Stage 8 contains a task of very large size (4035 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "merchant_df = transaction_sdf.join(\n",
    "    spark.createDataFrame(id_df),\n",
    "    on = 'user_id'\n",
    ").join(\n",
    "    spark.createDataFrame(consumer_df),\n",
    "    on = 'consumer_id'\n",
    ").groupBy(\n",
    "    'merchant_abn', 'poa'\n",
    ").count().toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_propn(df):\n",
    "    df['propn'] = df['count']/df['count'].sum()\n",
    "    return df\n",
    "merchant_df = merchant_df.groupby('merchant_abn').apply(get_propn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join to age data and scale the values according to the proportion of customers from each postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Joins merchantsand poa data with abs data for population by age for each poa\n",
    "merchant_df = pd.merge(merchant_df, age_df, on = 'poa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 34312)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/root/.virtualenvs/ads_proj2/lib/python3.10/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/root/.virtualenvs/ads_proj2/lib/python3.10/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/root/.virtualenvs/ads_proj2/lib/python3.10/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/root/.virtualenvs/ads_proj2/lib/python3.10/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Creates scaled version of each population metric by age\n",
    "for col in age_df.columns:\n",
    "    if col.startswith('age'):\n",
    "        merchant_df[col] = merchant_df[col]*merchant_df['propn']\n",
    "\n",
    "merchant_df = merchant_df.drop(['poa', 'count', 'propn'], axis = 1).groupby(['merchant_abn', 'gender']).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result is an estimate of the probability that a given customer comes from each age group (assumes that all customers are above the age of 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age_18_24</th>\n",
       "      <th>age_25_34</th>\n",
       "      <th>age_35_44</th>\n",
       "      <th>age_45_54</th>\n",
       "      <th>age_55_64</th>\n",
       "      <th>age_65+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_abn</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10023283211</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.090436</td>\n",
       "      <td>0.155516</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.1675</td>\n",
       "      <td>0.175922</td>\n",
       "      <td>0.255115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age_18_24  age_25_34  age_35_44  age_45_54  age_55_64  \\\n",
       "merchant_abn gender                                                          \n",
       "10023283211  Female   0.090436   0.155516   0.155512     0.1675   0.175922   \n",
       "\n",
       "                      age_65+  \n",
       "merchant_abn gender            \n",
       "10023283211  Female  0.255115  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "prob_bnpl = 0.05\n",
    "prob_female_g_bnpl = 0.57\n",
    "prob_male_g_bnpl = 0.43\n",
    "\n",
    "prob_age_g_bnpl = pd.Series(data = {'age_18_24' : 0.26, 'age_25_34' : 0.35, 'age_35_44' : 0.2, 'age_45_54' : 0.12, 'age_55_64' : 0.04,'age_65+' : 0.01})\n",
    "\n",
    "prob_bnpl_g_age_m = prob_age_g_bnpl*prob_male_g_bnpl*prob_bnpl/aus_age_m/aus_prob_m\n",
    "prob_bnpl_g_age_f = prob_age_g_bnpl*prob_female_g_bnpl*prob_bnpl/aus_age_f/(1-aus_prob_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_bnpl(row):\n",
    "    if row.name[1] == 'Male':\n",
    "        return (row*prob_bnpl_g_age_m).sum()\n",
    "    if row.name[1] == 'Female':\n",
    "        return (row*prob_bnpl_g_age_f).sum()\n",
    "\n",
    "merchant_df['weight'] = merchant_df.apply(get_prob_bnpl, axis = 1)\n",
    "merchant_df = merchant_df[['weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_abn</th>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10023283211</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.049574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.038421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10142254217</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.049346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.038263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10165489824</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.051551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987905597</th>\n",
       "      <th>Male</th>\n",
       "      <td>0.037582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">99989036621</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.046277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.039041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">99990536339</th>\n",
       "      <th>Female</th>\n",
       "      <td>0.046267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>0.035790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8844 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       weight\n",
       "merchant_abn gender          \n",
       "10023283211  Female  0.049574\n",
       "             Male    0.038421\n",
       "10142254217  Female  0.049346\n",
       "             Male    0.038263\n",
       "10165489824  Female  0.051551\n",
       "...                       ...\n",
       "99987905597  Male    0.037582\n",
       "99989036621  Female  0.046277\n",
       "             Male    0.039041\n",
       "99990536339  Female  0.046267\n",
       "             Male    0.035790\n",
       "\n",
       "[8844 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merchant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_df.to_parquet('../data/curated/merchant_gender_weights.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
